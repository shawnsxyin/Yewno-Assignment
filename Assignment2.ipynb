{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smart Beta Strategy\n",
    "\n",
    "Use machine learning models select factors and stocks to predict benchmark return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is pulled out from JoinQuant. All the data is in Chinese stock market. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auth success\n"
     ]
    }
   ],
   "source": [
    "auth('13637671410','zq13637671410')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.svm import SVR  \n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from jqdatasdk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Creat functions extract financial ratio data from Joinquant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected factors: \n",
    "\n",
    "Valuation factors: total owner equities/market capitalization(B/M), basic earning per share(EPS), price earning ratio(PE Ratio); \n",
    "\n",
    "Growth factors: net profit/total owner equities(ROE), net profit/total assets(ROA), total profit/operating revenue(GP/R), net profit/operating revenue(P/R)\n",
    "\n",
    "Capital structure factors: total liability/total assets(L/A), fixed assets/total assets(FAP), circulating market capitalization(CMV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['m_cap','B/M','EPS','PEG','ROE','ROA','GP/R','P/R','L/A','FAP','CMV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors(fdate,factors):\n",
    "    ## pull out the factors in Shanghai Stock Exchange Market data\n",
    "    stock_set = get_index_stocks('000001.XSHG',fdate)\n",
    "    q = query(\n",
    "        valuation.code,\n",
    "        valuation.market_cap,\n",
    "        balance.total_owner_equities/valuation.market_cap/100000000,\n",
    "        income.basic_eps,\n",
    "        valuation.pe_ratio,\n",
    "        income.net_profit/balance.total_owner_equities,\n",
    "        income.net_profit/balance.total_assets,\n",
    "        income.total_profit/income.operating_revenue,\n",
    "        income.net_profit/income.operating_revenue,\n",
    "        balance.total_liability/balance.total_assets,\n",
    "        balance.fixed_assets/balance.total_assets,\n",
    "        valuation.circulating_market_cap\n",
    "        ).filter(\n",
    "        valuation.code.in_(stock_set),\n",
    "        valuation.circulating_market_cap\n",
    "    )\n",
    "    fdf = get_fundamentals(q, date=fdate)\n",
    "    fdf.index = fdf['code']\n",
    "    fdf.columns = ['code'] + factors\n",
    "    fdf = fdf.drop('code',axis=1)\n",
    "    \n",
    "    ## standardized factors except m_cap, m_cap is not in the model but just for ranking and extracting the top stocks. \n",
    "    fdf_standard = pd.DataFrame()\n",
    "    fdf_standard['m_cap'] = fdf['m_cap']\n",
    "    for i in range(1,fdf.shape[1]): \n",
    "        col = fdf.columns[i]\n",
    "        fdf_standard[col] = (fdf[col] - fdf[col].mean())/fdf[col].std()\n",
    "        \n",
    "    return fdf_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_cap</th>\n",
       "      <th>B/M</th>\n",
       "      <th>EPS</th>\n",
       "      <th>PEG</th>\n",
       "      <th>ROE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>GP/R</th>\n",
       "      <th>P/R</th>\n",
       "      <th>L/A</th>\n",
       "      <th>FAP</th>\n",
       "      <th>CMV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600000.XSHG</th>\n",
       "      <td>3143.6079</td>\n",
       "      <td>1.984293</td>\n",
       "      <td>1.376447</td>\n",
       "      <td>-0.084399</td>\n",
       "      <td>0.118240</td>\n",
       "      <td>-0.548678</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>0.122015</td>\n",
       "      <td>2.016591</td>\n",
       "      <td>-1.156201</td>\n",
       "      <td>3.800616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600004.XSHG</th>\n",
       "      <td>209.6222</td>\n",
       "      <td>0.247869</td>\n",
       "      <td>-0.087386</td>\n",
       "      <td>-0.056103</td>\n",
       "      <td>-0.051952</td>\n",
       "      <td>-0.221850</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>-0.123894</td>\n",
       "      <td>3.341531</td>\n",
       "      <td>0.057836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600006.XSHG</th>\n",
       "      <td>76.6000</td>\n",
       "      <td>0.742517</td>\n",
       "      <td>-0.275057</td>\n",
       "      <td>-0.057018</td>\n",
       "      <td>-0.034849</td>\n",
       "      <td>-0.292729</td>\n",
       "      <td>-0.001901</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.485515</td>\n",
       "      <td>-0.644283</td>\n",
       "      <td>-0.119957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600007.XSHG</th>\n",
       "      <td>142.8327</td>\n",
       "      <td>-0.439869</td>\n",
       "      <td>0.175353</td>\n",
       "      <td>-0.046390</td>\n",
       "      <td>0.077012</td>\n",
       "      <td>0.265706</td>\n",
       "      <td>0.107064</td>\n",
       "      <td>0.087774</td>\n",
       "      <td>-0.233304</td>\n",
       "      <td>-0.147087</td>\n",
       "      <td>-0.031433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600008.XSHG</th>\n",
       "      <td>196.1480</td>\n",
       "      <td>0.762670</td>\n",
       "      <td>-0.329482</td>\n",
       "      <td>-0.010706</td>\n",
       "      <td>-0.069130</td>\n",
       "      <td>-0.475047</td>\n",
       "      <td>0.030833</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>1.046142</td>\n",
       "      <td>-0.579844</td>\n",
       "      <td>-0.000052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 m_cap       B/M       EPS       PEG       ROE       ROA  \\\n",
       "code                                                                       \n",
       "600000.XSHG  3143.6079  1.984293  1.376447 -0.084399  0.118240 -0.548678   \n",
       "600004.XSHG   209.6222  0.247869 -0.087386 -0.056103 -0.051952 -0.221850   \n",
       "600006.XSHG    76.6000  0.742517 -0.275057 -0.057018 -0.034849 -0.292729   \n",
       "600007.XSHG   142.8327 -0.439869  0.175353 -0.046390  0.077012  0.265706   \n",
       "600008.XSHG   196.1480  0.762670 -0.329482 -0.010706 -0.069130 -0.475047   \n",
       "\n",
       "                 GP/R       P/R       L/A       FAP       CMV  \n",
       "code                                                           \n",
       "600000.XSHG  0.128186  0.122015  2.016591 -1.156201  3.800616  \n",
       "600004.XSHG  0.042328  0.039278 -0.123894  3.341531  0.057836  \n",
       "600006.XSHG -0.001901  0.011813  0.485515 -0.644283 -0.119957  \n",
       "600007.XSHG  0.107064  0.087774 -0.233304 -0.147087 -0.031433  \n",
       "600008.XSHG  0.030833  0.027988  1.046142 -0.579844 -0.000052  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check a sample\n",
    "fdf = get_factors('2018-12-01',factors)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Get all dates from the selected time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get monthly dates from 2013-01-01 to 2017-12-01\n",
    "result = []\n",
    "today = datetime.date(2017,12,1)\n",
    "current = datetime.date(2013, 1, 1)    \n",
    "\n",
    "while current <= today:\n",
    "    result.append(current.strftime('%Y-%m-%d'))\n",
    "    current += relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Extract data and store them into a dictionary by dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf_dict = {}\n",
    "for x in result:\n",
    "    fdf=get_factors(x,factors)\n",
    "    fdf_dict[x] = fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save data into csv files\n",
    "for x in result:\n",
    "    fdf_dict[x].to_csv('data/'+ x+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dates for calculating benchmark\n",
    "result1 = []\n",
    "today1 = datetime.date(2018,1,1)\n",
    "current1 = datetime.date(2013, 1, 1)    \n",
    "\n",
    "while current1 <= today1:\n",
    "    result1.append(current1.strftime('%Y-%m-%d'))\n",
    "    current1 += relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Calculating Benchmark return for all dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use 000001.XSHG (Shanghai Exchange Stock Index) as the benchmark, and pull out the return\n",
    "def caculate_benchmark_monthly_return(startdate,enddate,nextdate):\n",
    "\n",
    "    close1 = get_price(['000001.XSHG'],startdate,enddate,'daily',['close'])['close']\n",
    "    close2 = get_price(['000001.XSHG'],enddate, nextdate, 'daily',['close'])['close']\n",
    "    benchmark_return = (close2.ix[0,:]/close1.ix[0,:]-1).sum()\n",
    "    \n",
    "    return benchmark_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench=pd.DataFrame()\n",
    "for i in range(0,len(result1)-2):\n",
    "    bench['return_'+result1[i+1]]=pd.Series(caculate_benchmark_monthly_return(result1[i],result1[i+1],result1[i+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 1)\n",
      "                     return\n",
      "return_2013-02-01  0.062375\n",
      "return_2013-03-01 -0.024603\n",
      "return_2013-04-01 -0.053024\n",
      "return_2013-05-01 -0.026975\n",
      "return_2013-06-01  0.057554\n"
     ]
    }
   ],
   "source": [
    "bench_r=bench.T\n",
    "bench_r.columns = ['return']\n",
    "print(bench_r.shape)\n",
    "print(bench_r.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) pull out Capitalization and extract top 300 stocks data according to the mean capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_cap_2013-01-01</th>\n",
       "      <th>m_cap_2013-02-01</th>\n",
       "      <th>m_cap_2013-03-01</th>\n",
       "      <th>m_cap_2013-04-01</th>\n",
       "      <th>m_cap_2013-05-01</th>\n",
       "      <th>m_cap_2013-06-01</th>\n",
       "      <th>m_cap_2013-07-01</th>\n",
       "      <th>m_cap_2013-08-01</th>\n",
       "      <th>m_cap_2013-09-01</th>\n",
       "      <th>m_cap_2013-10-01</th>\n",
       "      <th>...</th>\n",
       "      <th>m_cap_2017-03-01</th>\n",
       "      <th>m_cap_2017-04-01</th>\n",
       "      <th>m_cap_2017-05-01</th>\n",
       "      <th>m_cap_2017-06-01</th>\n",
       "      <th>m_cap_2017-07-01</th>\n",
       "      <th>m_cap_2017-08-01</th>\n",
       "      <th>m_cap_2017-09-01</th>\n",
       "      <th>m_cap_2017-10-01</th>\n",
       "      <th>m_cap_2017-11-01</th>\n",
       "      <th>m_cap_2017-12-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600000.XSHG</th>\n",
       "      <td>1850.42</td>\n",
       "      <td>2229.0901</td>\n",
       "      <td>2083.5901</td>\n",
       "      <td>1874.67</td>\n",
       "      <td>1842.96</td>\n",
       "      <td>1953.02</td>\n",
       "      <td>1523.99</td>\n",
       "      <td>1490.41</td>\n",
       "      <td>1676.95</td>\n",
       "      <td>1882.14</td>\n",
       "      <td>...</td>\n",
       "      <td>3579.99</td>\n",
       "      <td>3461.0901</td>\n",
       "      <td>3288.1399</td>\n",
       "      <td>3631.0063</td>\n",
       "      <td>3555.1262</td>\n",
       "      <td>3774.3354</td>\n",
       "      <td>3588.8506</td>\n",
       "      <td>3777.6128</td>\n",
       "      <td>3680.7510</td>\n",
       "      <td>3789.3535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600004.XSHG</th>\n",
       "      <td>81.54</td>\n",
       "      <td>87.1700</td>\n",
       "      <td>85.5600</td>\n",
       "      <td>79.58</td>\n",
       "      <td>78.89</td>\n",
       "      <td>81.08</td>\n",
       "      <td>72.56</td>\n",
       "      <td>70.04</td>\n",
       "      <td>77.86</td>\n",
       "      <td>77.86</td>\n",
       "      <td>...</td>\n",
       "      <td>172.74</td>\n",
       "      <td>183.3200</td>\n",
       "      <td>184.4500</td>\n",
       "      <td>212.5466</td>\n",
       "      <td>263.4459</td>\n",
       "      <td>278.5305</td>\n",
       "      <td>276.8751</td>\n",
       "      <td>270.8741</td>\n",
       "      <td>295.2920</td>\n",
       "      <td>290.7395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600005.XSHG</th>\n",
       "      <td>279.60</td>\n",
       "      <td>299.7900</td>\n",
       "      <td>296.7600</td>\n",
       "      <td>276.57</td>\n",
       "      <td>260.42</td>\n",
       "      <td>267.49</td>\n",
       "      <td>225.09</td>\n",
       "      <td>230.14</td>\n",
       "      <td>237.20</td>\n",
       "      <td>242.25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600006.XSHG</th>\n",
       "      <td>59.80</td>\n",
       "      <td>64.0000</td>\n",
       "      <td>62.8000</td>\n",
       "      <td>57.80</td>\n",
       "      <td>59.20</td>\n",
       "      <td>66.80</td>\n",
       "      <td>56.60</td>\n",
       "      <td>55.60</td>\n",
       "      <td>59.00</td>\n",
       "      <td>60.40</td>\n",
       "      <td>...</td>\n",
       "      <td>146.20</td>\n",
       "      <td>137.6000</td>\n",
       "      <td>126.2000</td>\n",
       "      <td>110.6000</td>\n",
       "      <td>117.0000</td>\n",
       "      <td>123.2000</td>\n",
       "      <td>118.8000</td>\n",
       "      <td>138.2000</td>\n",
       "      <td>127.0000</td>\n",
       "      <td>119.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600007.XSHG</th>\n",
       "      <td>115.74</td>\n",
       "      <td>114.2300</td>\n",
       "      <td>120.9700</td>\n",
       "      <td>114.23</td>\n",
       "      <td>104.86</td>\n",
       "      <td>112.92</td>\n",
       "      <td>92.67</td>\n",
       "      <td>92.37</td>\n",
       "      <td>110.70</td>\n",
       "      <td>113.52</td>\n",
       "      <td>...</td>\n",
       "      <td>200.15</td>\n",
       "      <td>201.5600</td>\n",
       "      <td>201.4600</td>\n",
       "      <td>206.9966</td>\n",
       "      <td>209.6155</td>\n",
       "      <td>198.6361</td>\n",
       "      <td>199.8449</td>\n",
       "      <td>189.8728</td>\n",
       "      <td>182.8218</td>\n",
       "      <td>175.3679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             m_cap_2013-01-01  m_cap_2013-02-01  m_cap_2013-03-01  \\\n",
       "code                                                                \n",
       "600000.XSHG           1850.42         2229.0901         2083.5901   \n",
       "600004.XSHG             81.54           87.1700           85.5600   \n",
       "600005.XSHG            279.60          299.7900          296.7600   \n",
       "600006.XSHG             59.80           64.0000           62.8000   \n",
       "600007.XSHG            115.74          114.2300          120.9700   \n",
       "\n",
       "             m_cap_2013-04-01  m_cap_2013-05-01  m_cap_2013-06-01  \\\n",
       "code                                                                \n",
       "600000.XSHG           1874.67           1842.96           1953.02   \n",
       "600004.XSHG             79.58             78.89             81.08   \n",
       "600005.XSHG            276.57            260.42            267.49   \n",
       "600006.XSHG             57.80             59.20             66.80   \n",
       "600007.XSHG            114.23            104.86            112.92   \n",
       "\n",
       "             m_cap_2013-07-01  m_cap_2013-08-01  m_cap_2013-09-01  \\\n",
       "code                                                                \n",
       "600000.XSHG           1523.99           1490.41           1676.95   \n",
       "600004.XSHG             72.56             70.04             77.86   \n",
       "600005.XSHG            225.09            230.14            237.20   \n",
       "600006.XSHG             56.60             55.60             59.00   \n",
       "600007.XSHG             92.67             92.37            110.70   \n",
       "\n",
       "             m_cap_2013-10-01        ...         m_cap_2017-03-01  \\\n",
       "code                                 ...                            \n",
       "600000.XSHG           1882.14        ...                  3579.99   \n",
       "600004.XSHG             77.86        ...                   172.74   \n",
       "600005.XSHG            242.25        ...                      NaN   \n",
       "600006.XSHG             60.40        ...                   146.20   \n",
       "600007.XSHG            113.52        ...                   200.15   \n",
       "\n",
       "             m_cap_2017-04-01  m_cap_2017-05-01  m_cap_2017-06-01  \\\n",
       "code                                                                \n",
       "600000.XSHG         3461.0901         3288.1399         3631.0063   \n",
       "600004.XSHG          183.3200          184.4500          212.5466   \n",
       "600005.XSHG               NaN               NaN               NaN   \n",
       "600006.XSHG          137.6000          126.2000          110.6000   \n",
       "600007.XSHG          201.5600          201.4600          206.9966   \n",
       "\n",
       "             m_cap_2017-07-01  m_cap_2017-08-01  m_cap_2017-09-01  \\\n",
       "code                                                                \n",
       "600000.XSHG         3555.1262         3774.3354         3588.8506   \n",
       "600004.XSHG          263.4459          278.5305          276.8751   \n",
       "600005.XSHG               NaN               NaN               NaN   \n",
       "600006.XSHG          117.0000          123.2000          118.8000   \n",
       "600007.XSHG          209.6155          198.6361          199.8449   \n",
       "\n",
       "             m_cap_2017-10-01  m_cap_2017-11-01  m_cap_2017-12-01  \n",
       "code                                                               \n",
       "600000.XSHG         3777.6128         3680.7510         3789.3535  \n",
       "600004.XSHG          270.8741          295.2920          290.7395  \n",
       "600005.XSHG               NaN               NaN               NaN  \n",
       "600006.XSHG          138.2000          127.0000          119.2000  \n",
       "600007.XSHG          189.8728          182.8218          175.3679  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pull out capitalization\n",
    "actual=pd.DataFrame()\n",
    "mkt_cap=pd.DataFrame()\n",
    "for x in result:\n",
    "    df=fdf_dict[x]\n",
    "    actual['CMV_'+x]=pd.Series(df['CMV'].fillna(0))\n",
    "    mkt_cap['m_cap_'+x]=pd.Series(df['m_cap'].fillna(0))\n",
    "mkt_cap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate mean and rank\n",
    "mkt_cap['mean'] = mkt_cap.mean(axis=1)\n",
    "mkt_cap_s=mkt_cap.sort_index(by='mean',ascending=False)\n",
    "slist = list(mkt_cap_s.index[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get top 300 data into a sub dictionary\n",
    "sub_dict={}\n",
    "for x in result:\n",
    "    sub_dict[x]=fdf_dict[x].loc[slist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) calculate return for 300 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_stock_monthly_return(stock,startdate,enddate,nextdate):\n",
    "\n",
    "    close1 = get_price(stock,startdate,enddate,'daily',['close'])['close']\n",
    "    close2 = get_price(stock,enddate, nextdate, 'daily',['close'])['close']\n",
    "    stock_return = (close2.ix[0,:]/close1.ix[0,:]-1)\n",
    "    return stock_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=caculate_stock_monthly_return(slist, '2013-01-01', '2013-02-01','2013-03-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_r=pd.DataFrame()\n",
    "for i in range(0,len(result1)-2):\n",
    "    stock_r['return_'+result1[i+1]]=pd.Series(caculate_stock_monthly_return(slist,result1[i],result1[i+1],result1[i+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return_2013-02-01</th>\n",
       "      <th>return_2013-03-01</th>\n",
       "      <th>return_2013-04-01</th>\n",
       "      <th>return_2013-05-01</th>\n",
       "      <th>return_2013-06-01</th>\n",
       "      <th>return_2013-07-01</th>\n",
       "      <th>return_2013-08-01</th>\n",
       "      <th>return_2013-09-01</th>\n",
       "      <th>return_2013-10-01</th>\n",
       "      <th>return_2013-11-01</th>\n",
       "      <th>...</th>\n",
       "      <th>return_2017-03-01</th>\n",
       "      <th>return_2017-04-01</th>\n",
       "      <th>return_2017-05-01</th>\n",
       "      <th>return_2017-06-01</th>\n",
       "      <th>return_2017-07-01</th>\n",
       "      <th>return_2017-08-01</th>\n",
       "      <th>return_2017-09-01</th>\n",
       "      <th>return_2017-10-01</th>\n",
       "      <th>return_2017-11-01</th>\n",
       "      <th>return_2017-12-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>601398.XSHG</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>-0.061920</td>\n",
       "      <td>-0.026403</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>-0.028939</td>\n",
       "      <td>-0.003311</td>\n",
       "      <td>-0.006645</td>\n",
       "      <td>-0.006689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026379</td>\n",
       "      <td>0.037383</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>-0.012346</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.043233</td>\n",
       "      <td>0.052252</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>-0.032590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601857.XSHG</th>\n",
       "      <td>0.026415</td>\n",
       "      <td>-0.030637</td>\n",
       "      <td>-0.035398</td>\n",
       "      <td>-0.030144</td>\n",
       "      <td>0.012162</td>\n",
       "      <td>-0.085447</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>-0.031944</td>\n",
       "      <td>0.031564</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038508</td>\n",
       "      <td>-0.033792</td>\n",
       "      <td>-0.034974</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>-0.009211</td>\n",
       "      <td>0.063745</td>\n",
       "      <td>-0.017478</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>0.052363</td>\n",
       "      <td>-0.027913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601939.XSHG</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.023669</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>-0.046243</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>-0.018127</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034549</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>-0.016364</td>\n",
       "      <td>0.085028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109029</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>0.025954</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>-0.010370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601288.XSHG</th>\n",
       "      <td>0.086957</td>\n",
       "      <td>-0.057778</td>\n",
       "      <td>-0.094340</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.015464</td>\n",
       "      <td>-0.035533</td>\n",
       "      <td>-0.005263</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>-0.006579</td>\n",
       "      <td>0.076159</td>\n",
       "      <td>-0.015385</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>-0.008427</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>-0.013850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601988.XSHG</th>\n",
       "      <td>0.070093</td>\n",
       "      <td>-0.056769</td>\n",
       "      <td>-0.027778</td>\n",
       "      <td>-0.019048</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>-0.023364</td>\n",
       "      <td>-0.009569</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>-0.032836</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>-0.011765</td>\n",
       "      <td>0.122024</td>\n",
       "      <td>0.061008</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.051020</td>\n",
       "      <td>0.002688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             return_2013-02-01  return_2013-03-01  return_2013-04-01  \\\n",
       "601398.XSHG           0.055556          -0.061920          -0.026403   \n",
       "601857.XSHG           0.026415          -0.030637          -0.035398   \n",
       "601939.XSHG           0.076923          -0.071429          -0.023669   \n",
       "601288.XSHG           0.086957          -0.057778          -0.094340   \n",
       "601988.XSHG           0.070093          -0.056769          -0.027778   \n",
       "\n",
       "             return_2013-05-01  return_2013-06-01  return_2013-07-01  \\\n",
       "601398.XSHG           0.003390           0.033784           0.016340   \n",
       "601857.XSHG          -0.030144           0.012162          -0.085447   \n",
       "601939.XSHG           0.027273           0.020649          -0.046243   \n",
       "601288.XSHG           0.010417           0.015464          -0.035533   \n",
       "601988.XSHG          -0.019048           0.038835          -0.023364   \n",
       "\n",
       "             return_2013-08-01  return_2013-09-01  return_2013-10-01  \\\n",
       "601398.XSHG          -0.028939          -0.003311          -0.006645   \n",
       "601857.XSHG           0.051095          -0.031944           0.031564   \n",
       "601939.XSHG           0.003030          -0.018127           0.012308   \n",
       "601288.XSHG          -0.005263          -0.005291           0.021277   \n",
       "601988.XSHG          -0.009569          -0.014493           0.049020   \n",
       "\n",
       "             return_2013-11-01        ...          return_2017-03-01  \\\n",
       "601398.XSHG          -0.006689        ...                   0.026379   \n",
       "601857.XSHG          -0.005563        ...                  -0.038508   \n",
       "601939.XSHG           0.006079        ...                   0.034549   \n",
       "601288.XSHG           0.015625        ...                   0.024221   \n",
       "601988.XSHG           0.014019        ...                   0.034056   \n",
       "\n",
       "             return_2017-04-01  return_2017-05-01  return_2017-06-01  \\\n",
       "601398.XSHG           0.037383          -0.006757           0.102041   \n",
       "601857.XSHG          -0.033792          -0.034974           0.020134   \n",
       "601939.XSHG           0.020408          -0.016364           0.085028   \n",
       "601288.XSHG           0.027027          -0.006579           0.076159   \n",
       "601988.XSHG           0.002994          -0.032836           0.049383   \n",
       "\n",
       "             return_2017-07-01  return_2017-08-01  return_2017-09-01  \\\n",
       "601398.XSHG          -0.012346           0.108333           0.043233   \n",
       "601857.XSHG          -0.009211           0.063745          -0.017478   \n",
       "601939.XSHG           0.000000           0.109029           0.006144   \n",
       "601288.XSHG          -0.015385           0.112500          -0.008427   \n",
       "601988.XSHG          -0.011765           0.122024           0.061008   \n",
       "\n",
       "             return_2017-10-01  return_2017-11-01  return_2017-12-01  \n",
       "601398.XSHG           0.052252          -0.001712          -0.032590  \n",
       "601857.XSHG          -0.005083           0.052363          -0.027913  \n",
       "601939.XSHG           0.025954           0.004464          -0.010370  \n",
       "601288.XSHG           0.022663          -0.013850           0.000000  \n",
       "601988.XSHG          -0.020000          -0.051020           0.002688  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Variable selection - VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly pick one date data, and check if there is any high correlated factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_factors('2015-01-01',factors).loc[slist]\n",
    "#log_df=np.log(df)\n",
    "#log_df=log_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X = df[['B/M','EPS','PEG','ROE','ROA','P/R','L/A','FAP','CMV']].fillna(0)\n",
    "Y = stock_r['return_2015-01-01'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.763112</td>\n",
       "      <td>ROA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.622888</td>\n",
       "      <td>EPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.482211</td>\n",
       "      <td>P/R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.467764</td>\n",
       "      <td>ROE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.266231</td>\n",
       "      <td>L/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.230189</td>\n",
       "      <td>B/M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.227815</td>\n",
       "      <td>CMV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.159436</td>\n",
       "      <td>FAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.016889</td>\n",
       "      <td>PEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIF Factor features\n",
       "4    1.763112      ROA\n",
       "1    1.622888      EPS\n",
       "5    1.482211      P/R\n",
       "3    1.467764      ROE\n",
       "6    1.266231      L/A\n",
       "0    1.230189      B/M\n",
       "8    1.227815      CMV\n",
       "7    1.159436      FAP\n",
       "2    1.016889      PEG"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##testing multicolinearity of factors\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif.sort_values(by='VIF Factor', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) variable selection - multivariate linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly pick three dates data and run linear regression model, and remove insignificant factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>return_2015-01-01</td> <th>  R-squared:         </th> <td>   0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   40.22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 14 Dec 2018</td>  <th>  Prob (F-statistic):</th> <td>3.70e-46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:16:20</td>      <th>  Log-Likelihood:    </th> <td>  61.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>       <th>  AIC:               </th> <td>  -105.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   291</td>       <th>  BIC:               </th> <td>  -72.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B/M</th> <td>    0.0323</td> <td>    0.012</td> <td>    2.763</td> <td> 0.006</td> <td>    0.009</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPS</th> <td>    0.0110</td> <td>    0.010</td> <td>    1.061</td> <td> 0.290</td> <td>   -0.009</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PEG</th> <td>    0.0195</td> <td>    0.016</td> <td>    1.206</td> <td> 0.229</td> <td>   -0.012</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ROE</th> <td>    0.1754</td> <td>    0.030</td> <td>    5.909</td> <td> 0.000</td> <td>    0.117</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ROA</th> <td>   -0.0359</td> <td>    0.012</td> <td>   -3.009</td> <td> 0.003</td> <td>   -0.059</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P/R</th> <td>    3.2173</td> <td>    0.254</td> <td>   12.661</td> <td> 0.000</td> <td>    2.717</td> <td>    3.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>L/A</th> <td>    0.0907</td> <td>    0.014</td> <td>    6.623</td> <td> 0.000</td> <td>    0.064</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FAP</th> <td>    0.0007</td> <td>    0.012</td> <td>    0.061</td> <td> 0.951</td> <td>   -0.023</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CMV</th> <td>    0.0157</td> <td>    0.007</td> <td>    2.177</td> <td> 0.030</td> <td>    0.002</td> <td>    0.030</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>38.538</td> <th>  Durbin-Watson:     </th> <td>   1.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  62.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.763</td> <th>  Prob(JB):          </th> <td>2.21e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.644</td> <th>  Cond. No.          </th> <td>    42.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      return_2015-01-01   R-squared:                       0.554\n",
       "Model:                            OLS   Adj. R-squared:                  0.541\n",
       "Method:                 Least Squares   F-statistic:                     40.22\n",
       "Date:                Fri, 14 Dec 2018   Prob (F-statistic):           3.70e-46\n",
       "Time:                        13:16:20   Log-Likelihood:                 61.737\n",
       "No. Observations:                 300   AIC:                            -105.5\n",
       "Df Residuals:                     291   BIC:                            -72.14\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "B/M            0.0323      0.012      2.763      0.006       0.009       0.055\n",
       "EPS            0.0110      0.010      1.061      0.290      -0.009       0.031\n",
       "PEG            0.0195      0.016      1.206      0.229      -0.012       0.051\n",
       "ROE            0.1754      0.030      5.909      0.000       0.117       0.234\n",
       "ROA           -0.0359      0.012     -3.009      0.003      -0.059      -0.012\n",
       "P/R            3.2173      0.254     12.661      0.000       2.717       3.717\n",
       "L/A            0.0907      0.014      6.623      0.000       0.064       0.118\n",
       "FAP            0.0007      0.012      0.061      0.951      -0.023       0.025\n",
       "CMV            0.0157      0.007      2.177      0.030       0.002       0.030\n",
       "==============================================================================\n",
       "Omnibus:                       38.538   Durbin-Watson:                   1.667\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               62.885\n",
       "Skew:                           0.763   Prob(JB):                     2.21e-14\n",
       "Kurtosis:                       4.644   Cond. No.                         42.4\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=get_factors('2015-01-01',factors).loc[slist]\n",
    "X = df[['B/M','EPS','PEG','ROE','ROA','P/R','L/A','FAP','CMV']].fillna(0)\n",
    "mod=sm.OLS(Y,X).fit()\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>return_2015-01-01</td> <th>  R-squared:         </th> <td>   0.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   37.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 14 Dec 2018</td>  <th>  Prob (F-statistic):</th> <td>1.42e-43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:16:25</td>      <th>  Log-Likelihood:    </th> <td>  55.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>       <th>  AIC:               </th> <td>  -92.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   291</td>       <th>  BIC:               </th> <td>  -59.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B/M</th> <td>    0.0968</td> <td>    0.011</td> <td>    8.484</td> <td> 0.000</td> <td>    0.074</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPS</th> <td>    0.0231</td> <td>    0.013</td> <td>    1.777</td> <td> 0.077</td> <td>   -0.002</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PEG</th> <td>    2.0339</td> <td>    0.303</td> <td>    6.718</td> <td> 0.000</td> <td>    1.438</td> <td>    2.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ROE</th> <td>   -0.0248</td> <td>    0.241</td> <td>   -0.103</td> <td> 0.918</td> <td>   -0.500</td> <td>    0.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ROA</th> <td>   -0.0197</td> <td>    0.060</td> <td>   -0.329</td> <td> 0.743</td> <td>   -0.138</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P/R</th> <td>    0.1162</td> <td>    0.054</td> <td>    2.157</td> <td> 0.032</td> <td>    0.010</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>L/A</th> <td>    0.3472</td> <td>    0.095</td> <td>    3.657</td> <td> 0.000</td> <td>    0.160</td> <td>    0.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FAP</th> <td>   -0.0226</td> <td>    0.012</td> <td>   -1.854</td> <td> 0.065</td> <td>   -0.047</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CMV</th> <td>    0.0067</td> <td>    0.007</td> <td>    0.919</td> <td> 0.359</td> <td>   -0.008</td> <td>    0.021</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>68.777</td> <th>  Durbin-Watson:     </th> <td>   1.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 156.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.118</td> <th>  Prob(JB):          </th> <td>1.16e-34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.739</td> <th>  Cond. No.          </th> <td>    51.8</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      return_2015-01-01   R-squared:                       0.535\n",
       "Model:                            OLS   Adj. R-squared:                  0.521\n",
       "Method:                 Least Squares   F-statistic:                     37.25\n",
       "Date:                Fri, 14 Dec 2018   Prob (F-statistic):           1.42e-43\n",
       "Time:                        13:16:25   Log-Likelihood:                 55.477\n",
       "No. Observations:                 300   AIC:                            -92.95\n",
       "Df Residuals:                     291   BIC:                            -59.62\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "B/M            0.0968      0.011      8.484      0.000       0.074       0.119\n",
       "EPS            0.0231      0.013      1.777      0.077      -0.002       0.049\n",
       "PEG            2.0339      0.303      6.718      0.000       1.438       2.630\n",
       "ROE           -0.0248      0.241     -0.103      0.918      -0.500       0.450\n",
       "ROA           -0.0197      0.060     -0.329      0.743      -0.138       0.098\n",
       "P/R            0.1162      0.054      2.157      0.032       0.010       0.222\n",
       "L/A            0.3472      0.095      3.657      0.000       0.160       0.534\n",
       "FAP           -0.0226      0.012     -1.854      0.065      -0.047       0.001\n",
       "CMV            0.0067      0.007      0.919      0.359      -0.008       0.021\n",
       "==============================================================================\n",
       "Omnibus:                       68.777   Durbin-Watson:                   1.762\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              156.271\n",
       "Skew:                           1.118   Prob(JB):                     1.16e-34\n",
       "Kurtosis:                       5.739   Cond. No.                         51.8\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=get_factors('2016-03-01',factors).loc[slist]\n",
    "X = df[['B/M','EPS','PEG','ROE','ROA','P/R','L/A','FAP','CMV']].fillna(0)\n",
    "mod=sm.OLS(Y,X).fit()\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>return_2015-01-01</td> <th>  R-squared:         </th> <td>   0.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   35.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 14 Dec 2018</td>  <th>  Prob (F-statistic):</th> <td>4.07e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:16:29</td>      <th>  Log-Likelihood:    </th> <td>  51.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>       <th>  AIC:               </th> <td>  -85.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   291</td>       <th>  BIC:               </th> <td>  -52.55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B/M</th> <td>    0.0777</td> <td>    0.012</td> <td>    6.739</td> <td> 0.000</td> <td>    0.055</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPS</th> <td>    0.0086</td> <td>    0.010</td> <td>    0.851</td> <td> 0.395</td> <td>   -0.011</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PEG</th> <td>   -0.9279</td> <td>    0.229</td> <td>   -4.044</td> <td> 0.000</td> <td>   -1.380</td> <td>   -0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ROE</th> <td>   -0.4838</td> <td>    0.344</td> <td>   -1.406</td> <td> 0.161</td> <td>   -1.161</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ROA</th> <td>    0.0703</td> <td>    0.032</td> <td>    2.177</td> <td> 0.030</td> <td>    0.007</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P/R</th> <td>    0.0365</td> <td>    0.033</td> <td>    1.104</td> <td> 0.270</td> <td>   -0.029</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>L/A</th> <td>    0.1246</td> <td>    0.018</td> <td>    6.970</td> <td> 0.000</td> <td>    0.089</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FAP</th> <td>    0.0103</td> <td>    0.012</td> <td>    0.878</td> <td> 0.381</td> <td>   -0.013</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CMV</th> <td>    0.0138</td> <td>    0.007</td> <td>    1.989</td> <td> 0.048</td> <td>    0.000</td> <td>    0.027</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>38.797</td> <th>  Durbin-Watson:     </th> <td>   1.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  72.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.715</td> <th>  Prob(JB):          </th> <td>2.21e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.929</td> <th>  Cond. No.          </th> <td>    63.5</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      return_2015-01-01   R-squared:                       0.524\n",
       "Model:                            OLS   Adj. R-squared:                  0.510\n",
       "Method:                 Least Squares   F-statistic:                     35.63\n",
       "Date:                Fri, 14 Dec 2018   Prob (F-statistic):           4.07e-42\n",
       "Time:                        13:16:29   Log-Likelihood:                 51.944\n",
       "No. Observations:                 300   AIC:                            -85.89\n",
       "Df Residuals:                     291   BIC:                            -52.55\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "B/M            0.0777      0.012      6.739      0.000       0.055       0.100\n",
       "EPS            0.0086      0.010      0.851      0.395      -0.011       0.028\n",
       "PEG           -0.9279      0.229     -4.044      0.000      -1.380      -0.476\n",
       "ROE           -0.4838      0.344     -1.406      0.161      -1.161       0.193\n",
       "ROA            0.0703      0.032      2.177      0.030       0.007       0.134\n",
       "P/R            0.0365      0.033      1.104      0.270      -0.029       0.101\n",
       "L/A            0.1246      0.018      6.970      0.000       0.089       0.160\n",
       "FAP            0.0103      0.012      0.878      0.381      -0.013       0.033\n",
       "CMV            0.0138      0.007      1.989      0.048       0.000       0.027\n",
       "==============================================================================\n",
       "Omnibus:                       38.797   Durbin-Watson:                   1.663\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               72.101\n",
       "Skew:                           0.715   Prob(JB):                     2.21e-16\n",
       "Kurtosis:                       4.929   Cond. No.                         63.5\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=get_factors('2017-06-01',factors).loc[slist]\n",
    "X = df[['B/M','EPS','PEG','ROE','ROA','P/R','L/A','FAP','CMV']].fillna(0)\n",
    "mod=sm.OLS(Y,X).fit()\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_list = ['B/M', 'PEG', 'P/R', 'L/A', 'CMV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Machine Learning Models: SVR, Random Forest, Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=pd.DataFrame()\n",
    "err_reg=pd.DataFrame()\n",
    "mae_reg=pd.DataFrame()\n",
    "rmse_reg=pd.DataFrame()\n",
    "\n",
    "svrmod=pd.DataFrame()\n",
    "err_svr=pd.DataFrame()\n",
    "mae_svr=pd.DataFrame()\n",
    "rmse_svr=pd.DataFrame()\n",
    "\n",
    "rfmodel=pd.DataFrame()\n",
    "err_rf=pd.DataFrame()\n",
    "mae_rf=pd.DataFrame()\n",
    "rmse_rf=pd.DataFrame()\n",
    "\n",
    "NN=pd.DataFrame()\n",
    "err_nn=pd.DataFrame()\n",
    "mae_nn=pd.DataFrame()\n",
    "rmse_nn=pd.DataFrame()\n",
    "\n",
    "for i in range(1,60):\n",
    "    x=result[i]\n",
    "    df=sub_dict[x]\n",
    "    #log_df=np.log(df)\n",
    "    #log_df=log_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    X = df[['B/M', 'PEG', 'P/R', 'L/A', 'CMV']].fillna(0)\n",
    "    Y = stock_r['return_'+x].fillna(0)\n",
    "    \n",
    "    ## multivariate regression model\n",
    "    mod=sm.OLS(Y,X)\n",
    "    res=mod.fit()\n",
    "    reg['return_'+x]=pd.Series(res.predict(X),index=Y.index)\n",
    "    predictions0 = pd.DataFrame(res.predict(X))\n",
    "    predictions0.index=Y.index\n",
    "    predictions0.columns=['return']\n",
    "    err_reg['err_'+x]=pd.Series(abs(predictions0['return'] - Y))# Print out the abs error\n",
    "    mae_reg['mae_'+x]=pd.Series((abs(predictions0['return'] - Y)).mean())# Print out the mean absolute error (mae)\n",
    "    rmse_reg['rmse_'+x]=pd.Series( math.sqrt(((predictions0['return'] - Y)**2).mean()) )# Calculate rmse\n",
    "    \n",
    "    ## SVR model\n",
    "    svr = SVR(kernel='rbf', gamma=0.1) \n",
    "    model = svr.fit(X, Y)\n",
    "    svrmod['return_'+x]=pd.Series(model.predict(X),index=Y.index)\n",
    "    predictions1 = pd.DataFrame(model.predict(X))\n",
    "    predictions1.index=Y.index\n",
    "    predictions1.columns=['return']\n",
    "    err_svr['mae_'+x]=pd.Series(abs(predictions1['return'] - Y))\n",
    "    mae_svr['mae_'+x]=pd.Series(abs(predictions1['return'] - Y).mean())# Print out the mean absolute error (mae)\n",
    "    rmse_svr['rmse_'+x]=pd.Series( math.sqrt(((predictions1['return'] - Y)**2).mean()) )# Calculate rmse\n",
    "    \n",
    "    ## random forest model\n",
    "    rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "    rfmod=rf.fit(X, Y)\n",
    "    rfmodel['return_'+x]=pd.Series(rfmod.predict(X),index=Y.index)\n",
    "    predictions2 = pd.DataFrame(rfmod.predict(X))\n",
    "    predictions2.index=Y.index\n",
    "    predictions2.columns=['return']\n",
    "    err_rf['err_'+x]=pd.Series(abs(predictions2['return'] - Y))# Print out the abs error\n",
    "    mae_rf['mae_'+x]=pd.Series(abs(predictions2['return'] - Y).mean())# Print out the mean absolute error (mae)\n",
    "    rmse_rf['rmse_'+x]=pd.Series( math.sqrt(((predictions2['return'] - Y)**2).mean()) )# Calculate rmse\n",
    "  \n",
    "    ## neural network model\n",
    "    clf = MLPRegressor(hidden_layer_sizes=(3), activation='tanh', solver='lbfgs')\n",
    "    nnmod=clf.fit(X, Y) \n",
    "    NN['return_'+x]=pd.Series(nnmod.predict(X),index=Y.index)\n",
    "    predictions3 = pd.DataFrame(nnmod.predict(X))\n",
    "    predictions3.index=Y.index\n",
    "    predictions3.columns=['return']\n",
    "    err_nn['err_'+x]=pd.Series(abs(predictions3['return'] - Y))# Print out the abs error\n",
    "    mae_nn['mae_'+x]=pd.Series(abs(predictions3['return'] - Y).mean())# Print out the mean absolute error (mae)\n",
    "    rmse_nn['rmse_'+x]=pd.Series( math.sqrt(((predictions3['return'] - Y)**2).mean()) )# Calculate rmse\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Select Model based on MAE/RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.07051887786571352 RMSE: 0.10378027454721404\n"
     ]
    }
   ],
   "source": [
    "mae_reg_m=mae_reg.mean(axis=1)\n",
    "rmse_reg_m=rmse_reg.mean(axis=1)\n",
    "print('MAE:' ,mae_reg_m[0],'RMSE:',rmse_reg_m[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.06886984555245142 RMSE: 0.09800363791055651\n"
     ]
    }
   ],
   "source": [
    "mae_svr_m=mae_svr.mean(axis=1)\n",
    "rmse_svr_m=rmse_svr.mean(axis=1)\n",
    "print('MAE:' ,mae_svr_m[0],'RMSE:',rmse_svr_m[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.025735978884134352 RMSE: 0.03834188024272441\n"
     ]
    }
   ],
   "source": [
    "mae_rf_m=mae_rf.mean(axis=1)\n",
    "rmse_rf_m=rmse_rf.mean(axis=1)\n",
    "print('MAE:' ,mae_rf_m[0],'RMSE:',rmse_rf_m[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.06461351468311773 RMSE: 0.09320297229151003\n"
     ]
    }
   ],
   "source": [
    "mae_nn_m=mae_nn.mean(axis=1)\n",
    "rmse_nn_m=rmse_nn.mean(axis=1)\n",
    "print('MAE:' ,mae_nn_m[0],'RMSE:',rmse_nn_m[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to MAE and RMSE, SVR, RF, and NN are all better than linear regression model, and random forest is the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     importance\n",
      "CMV    0.271761\n",
      "P/R    0.212537\n",
      "PEG    0.186464\n",
      "L/A    0.169475\n",
      "B/M    0.159763\n"
     ]
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construct Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) equally weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select stocks according to the mean of the error, and select top 10 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024911550234833282\n"
     ]
    }
   ],
   "source": [
    "## tracking error -- regression\n",
    "err_reg['mean']=err_reg.mean(axis=1)\n",
    "err_reg_s=err_reg.sort_index(by='mean')\n",
    "stockset_reg = list(err_reg_s.index[:10])\n",
    "port_reg=reg.loc[stockset_reg]\n",
    "reg_r=port_reg.mean() ##assuming equally weighted\n",
    "tracking_err_reg = np.std(reg_r-bench_r['return'])\n",
    "print(tracking_err_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027717865828212847\n"
     ]
    }
   ],
   "source": [
    "## tracking error -- SVR\n",
    "err_svr['mean']=err_svr.mean(axis=1)\n",
    "err_svr_s=err_svr.sort_index(by='mean')\n",
    "stockset_svr = list(err_svr_s.index[:10])\n",
    "port_svr=svrmod.loc[stockset_svr]\n",
    "svr_r=port_svr.mean()\n",
    "tracking_err_svr = np.std(svr_r-bench_r['return'])\n",
    "print(tracking_err_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03457203611478055\n"
     ]
    }
   ],
   "source": [
    "## tracking error -- rf\n",
    "err_rf['mean']=err_rf.mean(axis=1)\n",
    "err_rf_s=err_rf.sort_index(by='mean')\n",
    "stockset_rf = list(err_rf_s.index[:10])\n",
    "port_rf=rfmodel.loc[stockset_rf]\n",
    "rf_r=port_rf.mean()\n",
    "tracking_err_rf = np.std(rf_r-bench_r['return'])\n",
    "print(tracking_err_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029250007263918215\n"
     ]
    }
   ],
   "source": [
    "## tracking error -- nn\n",
    "err_nn['mean']=err_nn.mean(axis=1)\n",
    "err_nn_s=err_nn.sort_index(by='mean')\n",
    "stockset_nn = list(err_nn_s.index[:10])\n",
    "port_nn=NN.loc[stockset_nn]\n",
    "nn_r=port_nn.mean()\n",
    "tracking_err_nn = np.std(nn_r-bench_r['return'])\n",
    "print(tracking_err_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Portfolio Optimization (using random forest based on the model selection in step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['601988.XSHG',\n",
       " '600015.XSHG',\n",
       " '601398.XSHG',\n",
       " '601818.XSHG',\n",
       " '601857.XSHG',\n",
       " '601288.XSHG',\n",
       " '600000.XSHG',\n",
       " '600377.XSHG',\n",
       " '600660.XSHG',\n",
       " '601328.XSHG']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockset_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'601988.XSHG': 0.0, '600015.XSHG': 1.9619569430550897e-17, '601398.XSHG': 0.148821974294187, '601818.XSHG': 1.7150700570641979e-16, '601857.XSHG': 0.0, '601288.XSHG': 0.0, '600000.XSHG': 0.13171356606143864, '600377.XSHG': 0.16617442132400467, '600660.XSHG': 0.5532900383203697, '601328.XSHG': 7.09015946811154e-18}\n"
     ]
    }
   ],
   "source": [
    "# Read in price data\n",
    "close = get_price(stockset_rf,'2013-01-01','2017-12-01','daily',['close'])['close']\n",
    "\n",
    "# Calculate expected returns and sample covariance\n",
    "mu = expected_returns.mean_historical_return(close)\n",
    "S = risk_models.sample_cov(close)\n",
    "\n",
    "# Optimise for maximal Sharpe ratio\n",
    "ef = EfficientFrontier(mu, S)\n",
    "raw_weights = ef.max_sharpe()\n",
    "print(raw_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected annual return: 27.8%\n",
      "Annual volatility: 24.9%\n",
      "Sharpe Ratio: 1.03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2776214538745265, 0.2491072301814984, 1.0267141455474125)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'600000.XSHG': 0.13846958037790516,\n",
       " '600015.XSHG': 0.08443204675672403,\n",
       " '600377.XSHG': 0.012096345774621303,\n",
       " '600660.XSHG': 0.2316302243960177,\n",
       " '601288.XSHG': -0.13720742979738948,\n",
       " '601328.XSHG': -0.1284996066992483,\n",
       " '601398.XSHG': 0.089980900221894,\n",
       " '601818.XSHG': -0.10262605977218188,\n",
       " '601857.XSHG': -0.3564112400023143,\n",
       " '601988.XSHG': 0.16813523874397174}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef = EfficientFrontier(mu, S, weight_bounds=(0, 1))\n",
    "ef.efficient_return(target_return=0.1, market_neutral=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=pd.DataFrame(raw_weights ,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601988.XSHG    0.000000e+00\n",
       "600015.XSHG    1.961957e-17\n",
       "601398.XSHG    1.488220e-01\n",
       "601818.XSHG    1.715070e-16\n",
       "601857.XSHG    0.000000e+00\n",
       "601288.XSHG    0.000000e+00\n",
       "600000.XSHG    1.317136e-01\n",
       "600377.XSHG    1.661744e-01\n",
       "600660.XSHG    5.532900e-01\n",
       "601328.XSHG    7.090159e-18\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r=pd.DataFrame()\n",
    "for i in range(1,60):\n",
    "    x=result[i]\n",
    "    p_r['return_'+x]=port_rf['return_'+x].dot(w.T)\n",
    "pr=p_r.T\n",
    "pr.columns = ['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036576165848521545"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te=np.std(pr['return']-bench_r['return'])\n",
    "te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Portfolio Optimization (using SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['600004.XSHG',\n",
       " '600015.XSHG',\n",
       " '600811.XSHG',\n",
       " '601818.XSHG',\n",
       " '600219.XSHG',\n",
       " '600350.XSHG',\n",
       " '600875.XSHG',\n",
       " '600377.XSHG',\n",
       " '600320.XSHG',\n",
       " '600548.XSHG']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockset_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'600004.XSHG': 0.43535688564846436, '600015.XSHG': 0.17964098611968793, '600811.XSHG': 1.9656585387162195e-16, '601818.XSHG': 2.387413183813081e-16, '600219.XSHG': 1.5563722186029416e-16, '600350.XSHG': 0.0, '600875.XSHG': 0.0, '600377.XSHG': 0.06216637294036528, '600320.XSHG': 0.0, '600548.XSHG': 0.32283575529148256}\n"
     ]
    }
   ],
   "source": [
    "# Read in price data\n",
    "close = get_price(stockset_svr,'2013-01-01','2017-12-01','daily',['close'])['close']\n",
    "\n",
    "# Calculate expected returns and sample covariance\n",
    "mu = expected_returns.mean_historical_return(close)\n",
    "S = risk_models.sample_cov(close)\n",
    "\n",
    "# Optimise for maximal Sharpe ratio\n",
    "ef = EfficientFrontier(mu, S)\n",
    "raw_weights = ef.max_sharpe()\n",
    "print(raw_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected annual return: 29.4%\n",
      "Annual volatility: 28.6%\n",
      "Sharpe Ratio: 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2943478447698406, 0.2858183733181779, 0.953269888825544)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'600004.XSHG': 0.2571037311521381,\n",
       " '600015.XSHG': 0.11769102660942511,\n",
       " '600219.XSHG': -0.04069176213102373,\n",
       " '600320.XSHG': 0.023240705928103494,\n",
       " '600350.XSHG': 0.05734906844965445,\n",
       " '600377.XSHG': -0.07061354872147159,\n",
       " '600548.XSHG': 0.1332736079214702,\n",
       " '600811.XSHG': -0.13071419656785926,\n",
       " '600875.XSHG': -0.21084992976307507,\n",
       " '601818.XSHG': -0.13578870287736167}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef = EfficientFrontier(mu, S, weight_bounds=(0, 1))\n",
    "ef.efficient_return(target_return=0.1, market_neutral=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=pd.DataFrame(raw_weights ,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600004.XSHG</th>\n",
       "      <td>4.353569e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600015.XSHG</th>\n",
       "      <td>1.796410e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600811.XSHG</th>\n",
       "      <td>1.965659e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601818.XSHG</th>\n",
       "      <td>2.387413e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600219.XSHG</th>\n",
       "      <td>1.556372e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600350.XSHG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600875.XSHG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600377.XSHG</th>\n",
       "      <td>6.216637e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600320.XSHG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600548.XSHG</th>\n",
       "      <td>3.228358e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "600004.XSHG  4.353569e-01\n",
       "600015.XSHG  1.796410e-01\n",
       "600811.XSHG  1.965659e-16\n",
       "601818.XSHG  2.387413e-16\n",
       "600219.XSHG  1.556372e-16\n",
       "600350.XSHG  0.000000e+00\n",
       "600875.XSHG  0.000000e+00\n",
       "600377.XSHG  6.216637e-02\n",
       "600320.XSHG  0.000000e+00\n",
       "600548.XSHG  3.228358e-01"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r=pd.DataFrame()\n",
    "for i in range(1,60):\n",
    "    x=result[i]\n",
    "    p_r['return_'+x]=port_svr['return_'+x].dot(w.T)\n",
    "pr=p_r.T\n",
    "pr.columns = ['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032524841223821724"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te=np.std(pr['return']-bench_r['return'])\n",
    "te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the model's performance, Random Forest model is the best model on predict the stock's returns according to the MAE and RMSE, but based on the tracking error, which is our final goal, using SVR to select top 10 stocks and construct portfolio both equally weight or using optimized weight has a smaller tracking error than random forest. And the MAE and RMSE are not as big as linear regression, so I recommend to use SVR and equally weight stocks as my strategy for portfolio construction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
